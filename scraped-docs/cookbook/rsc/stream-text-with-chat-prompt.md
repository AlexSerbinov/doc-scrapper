# Stream Text with Chat Prompt


---
url: https://ai-sdk.dev/cookbook/rsc/stream-text-with-chat-prompt
description: Learn how to stream text with chat prompt using the AI SDK and React Server Components.
---


# [Stream Text with Chat Prompt](#stream-text-with-chat-prompt)


Chat completion can sometimes take a long time to finish, especially when the response is big. In such cases, it is useful to stream the chat completion to the client in real-time. This allows the client to display the new message as it is being generated by the model, rather than have users wait for it to finish.

http://localhost:3000

User: How is it going?

Assistant: All good, how may I help you?

Why is the sky blue?

Send Message


## [Client](#client)


Let's create a simple conversation between a user and a model, and place a button that will call `continueConversation`.

app/page.tsx

```
'use client';import{ useState }from'react';import{Message, continueConversation }from'./actions';import{ readStreamableValue }from'ai/rsc';// Allow streaming responses up to 30 secondsexportconst maxDuration =30;exportdefaultfunctionHome(){const[conversation, setConversation]=useState<Message[]>([]);const[input, setInput]=useState<string>('');return(<div><div>{conversation.map((message, index)=>(<divkey={index}>{message.role}:{message.content}</div>))}</div><div><inputtype="text"value={input}onChange={event=>{setInput(event.target.value);}}/><button          onClick={async()=>{const{ messages, newMessage }=awaitcontinueConversation([...conversation,{ role:'user', content: input },]);let textContent ='';forawait(const delta ofreadStreamableValue(newMessage)){              textContent =`${textContent}${delta}`;setConversation([...messages,{ role:'assistant', content: textContent },]);}}}>SendMessage</button></div></div>);}
```


## [Server](#server)


Now, let's implement the `continueConversation` function that will insert the user's message into the conversation and stream back the new message.

app/actions.ts

```
'use server';import{ streamText }from'ai';import{ openai }from'@ai-sdk/openai';import{ createStreamableValue }from'ai/rsc';exportinterfaceMessage{  role:'user'|'assistant';  content:string;}exportasyncfunctioncontinueConversation(history:Message[]){'use server';const stream =createStreamableValue();(async()=>{const{ textStream }=streamText({      model:openai('gpt-3.5-turbo'),      system:"You are a dude that doesn't drop character until the DVD commentary.",      messages: history,});forawait(const text of textStream){      stream.update(text);}    stream.done();})();return{    messages: history,    newMessage: stream.value,};}
```
